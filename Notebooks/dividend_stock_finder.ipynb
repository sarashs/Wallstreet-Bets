{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67aef36c-01ec-4d40-825c-72a6714b6710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>isin</th>\n",
       "      <th>currency</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>united states</td>\n",
       "      <td>Boeing</td>\n",
       "      <td>Boeing Co</td>\n",
       "      <td>US0970231058</td>\n",
       "      <td>USD</td>\n",
       "      <td>BA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>united states</td>\n",
       "      <td>General Motors</td>\n",
       "      <td>General Motors Company</td>\n",
       "      <td>US37045V1008</td>\n",
       "      <td>USD</td>\n",
       "      <td>GM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>united states</td>\n",
       "      <td>Chevron</td>\n",
       "      <td>Chevron Corp</td>\n",
       "      <td>US1667641005</td>\n",
       "      <td>USD</td>\n",
       "      <td>CVX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>united states</td>\n",
       "      <td>Citigroup</td>\n",
       "      <td>Citigroup Inc</td>\n",
       "      <td>US1729674242</td>\n",
       "      <td>USD</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>united states</td>\n",
       "      <td>Bank of America</td>\n",
       "      <td>Bank of America Corp</td>\n",
       "      <td>US0605051046</td>\n",
       "      <td>USD</td>\n",
       "      <td>BAC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         country             name               full_name          isin  \\\n",
       "0  united states           Boeing               Boeing Co  US0970231058   \n",
       "1  united states   General Motors  General Motors Company  US37045V1008   \n",
       "2  united states          Chevron            Chevron Corp  US1667641005   \n",
       "3  united states        Citigroup           Citigroup Inc  US1729674242   \n",
       "4  united states  Bank of America    Bank of America Corp  US0605051046   \n",
       "\n",
       "  currency symbol  \n",
       "0      USD     BA  \n",
       "1      USD     GM  \n",
       "2      USD    CVX  \n",
       "3      USD      C  \n",
       "4      USD    BAC  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting all of the stocks in the US\n",
    "import investpy\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import pytz\n",
    "\n",
    "# Get list of all stocks in the US\n",
    "stocks = investpy.stocks.get_stocks(country='united states')\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c4127e6-1051-42f9-811b-973eee081e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "russel = pd.read_csv(\"russel1000.csv\")\n",
    "russel_tick = russel['Ticker'].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d3beb2e-1616-45d2-b92f-84a5c2cdab36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AAPL\n",
      "Fetching data for NVDA\n",
      "Fetching data for MSFT\n",
      "Fetching data for AMZN\n",
      "No dividend data for AMZN\n",
      "Fetching data for META\n",
      "Fetching data for GOOGL\n",
      "Fetching data for AVGO\n",
      "Fetching data for TSLA\n",
      "No dividend data for TSLA\n",
      "Fetching data for GOOG\n",
      "Fetching data for BRKB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BRKB: possibly delisted; no timezone found\n",
      "$BRKB: possibly delisted; no price data found  (period=5y) (Yahoo error = \"No data found, symbol may be delisted\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No dividend data for BRKB\n",
      "Fetching data for JPM\n",
      "Fetching data for LLY\n",
      "Fetching data for V\n",
      "Fetching data for XOM\n",
      "Fetching data for UNH\n",
      "Fetching data for COST\n",
      "Fetching data for MA\n",
      "Fetching data for NFLX\n",
      "No dividend data for NFLX\n",
      "Fetching data for WMT\n",
      "Fetching data for HD\n",
      "Fetching data for PG\n",
      "Fetching data for JNJ\n",
      "Fetching data for ABBV\n",
      "Fetching data for BAC\n",
      "Fetching data for CRM\n",
      "Fetching data for ORCL\n",
      "Fetching data for CVX\n",
      "Fetching data for KO\n",
      "Fetching data for WFC\n",
      "Fetching data for CSCO\n",
      "Fetching data for ACN\n",
      "Fetching data for PLTR\n",
      "No dividend data for PLTR\n",
      "Fetching data for IBM\n",
      "Fetching data for PM\n",
      "Fetching data for ABT\n",
      "Fetching data for GE\n",
      "Fetching data for MCD\n",
      "Fetching data for LIN\n",
      "Fetching data for ISRG\n",
      "No dividend data for ISRG\n",
      "Fetching data for MRK\n",
      "Fetching data for ADBE\n",
      "Fetching data for TMO\n",
      "Fetching data for GS\n",
      "Fetching data for NOW\n",
      "No dividend data for NOW\n",
      "Fetching data for DIS\n",
      "Fetching data for PEP\n",
      "Fetching data for QCOM\n",
      "Fetching data for T\n",
      "Fetching data for AMD\n",
      "No dividend data for AMD\n",
      "Fetching data for AXP\n",
      "Fetching data for VZ\n",
      "Fetching data for CAT\n",
      "Fetching data for SPGI\n",
      "Fetching data for BKNG\n",
      "Fetching data for TXN\n",
      "Fetching data for RTX\n",
      "Fetching data for UBER\n",
      "No dividend data for UBER\n",
      "Fetching data for MS\n",
      "Fetching data for INTU\n",
      "Fetching data for C\n",
      "Fetching data for AMGN\n",
      "Fetching data for BSX\n",
      "No dividend data for BSX\n",
      "Fetching data for PGR\n",
      "Fetching data for UNP\n",
      "Fetching data for PFE\n",
      "Fetching data for LOW\n",
      "Fetching data for BLK\n",
      "Fetching data for TJX\n",
      "Fetching data for AMAT\n",
      "Fetching data for NEE\n",
      "Fetching data for SYK\n",
      "Fetching data for CMCSA\n",
      "Fetching data for APP\n",
      "No dividend data for APP\n",
      "Fetching data for SCHW\n",
      "Fetching data for DHR\n",
      "Fetching data for HON\n",
      "Fetching data for FI\n",
      "No dividend data for FI\n",
      "Fetching data for BA\n",
      "Fetching data for GILD\n",
      "Fetching data for TMUS\n",
      "Fetching data for PANW\n",
      "No dividend data for PANW\n",
      "Fetching data for SBUX\n",
      "Fetching data for ADP\n",
      "Fetching data for COP\n",
      "Fetching data for ETN\n",
      "Fetching data for DE\n",
      "Fetching data for MDT\n",
      "Fetching data for BX\n",
      "Fetching data for VRTX\n",
      "No dividend data for VRTX\n",
      "Fetching data for MMC\n",
      "Fetching data for PLD\n",
      "Fetching data for ANET\n",
      "No dividend data for ANET\n",
      "Fetching data for MU\n",
      "Fetching data for BMY\n",
      "Fetching data for CB\n",
      "Fetching data for ADI\n",
      "Fetching data for LRCX\n",
      "Fetching data for CRWD\n",
      "No dividend data for CRWD\n",
      "Fetching data for KLAC\n",
      "Fetching data for INTC\n",
      "Fetching data for GEV\n",
      "Fetching data for CEG\n",
      "Fetching data for KKR\n",
      "Fetching data for ICE\n",
      "Fetching data for SPOT\n",
      "No dividend data for SPOT\n",
      "Fetching data for SO\n",
      "Fetching data for WELL\n",
      "Fetching data for WM\n",
      "Fetching data for MRVL\n",
      "Fetching data for MO\n",
      "Fetching data for ELV\n",
      "Fetching data for EQIX\n",
      "Fetching data for PH\n",
      "Fetching data for LMT\n",
      "Fetching data for AMT\n",
      "Fetching data for CME\n",
      "Fetching data for NKE\n",
      "Fetching data for DUK\n",
      "Fetching data for APO\n",
      "Fetching data for UPS\n",
      "Fetching data for SHW\n",
      "Fetching data for CVS\n",
      "Fetching data for MCO\n",
      "Fetching data for TT\n",
      "Fetching data for MDLZ\n",
      "Fetching data for APH\n",
      "Fetching data for MMM\n",
      "Fetching data for CDNS\n",
      "No dividend data for CDNS\n",
      "Fetching data for CI\n",
      "Fetching data for SNPS\n",
      "No dividend data for SNPS\n",
      "Fetching data for AJG\n",
      "Fetching data for PYPL\n",
      "No dividend data for PYPL\n",
      "Fetching data for CMG\n",
      "No dividend data for CMG\n",
      "Fetching data for XTSLA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$XTSLA: possibly delisted; no timezone found\n",
      "$XTSLA: possibly delisted; no price data found  (period=5y) (Yahoo error = \"No data found, symbol may be delisted\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No dividend data for XTSLA\n",
      "Fetching data for PNC\n",
      "Fetching data for MCK\n",
      "Fetching data for COF\n",
      "Fetching data for ORLY\n",
      "No dividend data for ORLY\n",
      "Fetching data for AON\n",
      "Fetching data for ITW\n",
      "Fetching data for DASH\n",
      "No dividend data for DASH\n",
      "Fetching data for CRH\n",
      "Fetching data for USB\n",
      "Fetching data for EOG\n",
      "Fetching data for MSI\n",
      "Fetching data for ZTS\n",
      "Fetching data for TDG\n",
      "Fetching data for FTNT\n",
      "No dividend data for FTNT\n",
      "Fetching data for CTAS\n",
      "Fetching data for EMR\n",
      "Fetching data for REGN\n",
      "No dividend data for REGN\n",
      "Fetching data for ABNB\n",
      "No dividend data for ABNB\n",
      "Fetching data for APD\n",
      "Fetching data for CL\n",
      "Fetching data for WMB\n",
      "Fetching data for ECL\n",
      "Fetching data for GD\n",
      "Fetching data for ADSK\n",
      "Fetching data for BDX\n",
      "Fetching data for MAR\n",
      "Fetching data for BK\n",
      "Fetching data for CSX\n",
      "Fetching data for HLT\n",
      "Fetching data for TFC\n",
      "Fetching data for RCL\n",
      "Fetching data for ROP\n",
      "Fetching data for FDX\n",
      "Fetching data for NOC\n",
      "Fetching data for SPG\n",
      "Fetching data for JCI\n",
      "Fetching data for TGT\n",
      "Fetching data for SNOW\n",
      "No dividend data for SNOW\n",
      "Fetching data for SLB\n",
      "Fetching data for AZO\n",
      "No dividend data for AZO\n",
      "Fetching data for HCA\n",
      "Fetching data for NSC\n",
      "Fetching data for AFL\n",
      "Fetching data for OKE\n",
      "Fetching data for VST\n",
      "Fetching data for FCX\n",
      "Fetching data for MSTR\n",
      "No dividend data for MSTR\n",
      "Fetching data for COIN\n",
      "No dividend data for COIN\n",
      "Fetching data for WDAY\n",
      "No dividend data for WDAY\n",
      "Fetching data for TRV\n",
      "Fetching data for CARR\n",
      "Fetching data for DLR\n",
      "Fetching data for PCAR\n",
      "Fetching data for HWM\n",
      "Fetching data for AEP\n",
      "Fetching data for NEM\n",
      "Fetching data for SRE\n",
      "Fetching data for AMP\n",
      "Fetching data for GM\n",
      "Fetching data for PSX\n",
      "Fetching data for MPC\n",
      "Fetching data for CPRT\n",
      "No dividend data for CPRT\n",
      "Fetching data for KMI\n",
      "Fetching data for NET\n",
      "No dividend data for NET\n",
      "Fetching data for CMI\n",
      "Fetching data for TEAM\n",
      "No dividend data for TEAM\n",
      "Fetching data for ALL\n",
      "Fetching data for DFS\n",
      "Fetching data for URI\n",
      "Fetching data for AXON\n",
      "No dividend data for AXON\n",
      "Fetching data for AIG\n",
      "Fetching data for MET\n",
      "Fetching data for LNG\n",
      "Fetching data for O\n",
      "Fetching data for RSG\n",
      "Fetching data for PAYX\n",
      "Fetching data for PSA\n",
      "Fetching data for XYZ\n",
      "No dividend data for XYZ\n",
      "Fetching data for D\n",
      "Fetching data for BKR\n",
      "Fetching data for ROST\n",
      "Fetching data for EW\n",
      "No dividend data for EW\n",
      "Fetching data for CTSH\n",
      "Fetching data for TRGP\n",
      "Fetching data for CTVA\n",
      "Fetching data for GWW\n",
      "Fetching data for KMB\n",
      "Fetching data for HOOD\n",
      "No dividend data for HOOD\n",
      "Fetching data for MSCI\n",
      "Fetching data for CBRE\n",
      "No dividend data for CBRE\n",
      "Fetching data for NU\n",
      "No dividend data for NU\n",
      "Fetching data for VLO\n",
      "Fetching data for KR\n",
      "Fetching data for LULU\n",
      "No dividend data for LULU\n",
      "Fetching data for EXC\n",
      "Fetching data for FAST\n",
      "Fetching data for FICO\n",
      "Fetching data for AME\n",
      "Fetching data for DAL\n",
      "Fetching data for GEHC\n",
      "Fetching data for KVUE\n",
      "Fetching data for PEG\n",
      "Fetching data for VRSK\n",
      "Fetching data for YUM\n",
      "Fetching data for PWR\n",
      "Fetching data for HES\n",
      "Fetching data for ODFL\n",
      "Fetching data for COR\n",
      "Fetching data for GLW\n",
      "Fetching data for PRU\n",
      "Fetching data for HUBS\n",
      "No dividend data for HUBS\n",
      "Fetching data for XEL\n",
      "Fetching data for DDOG\n",
      "No dividend data for DDOG\n",
      "Fetching data for OTIS\n",
      "Fetching data for IT\n",
      "Fetching data for A\n",
      "Fetching data for VRT\n",
      "Fetching data for CCI\n",
      "Fetching data for DHI\n",
      "Fetching data for FIS\n",
      "Fetching data for LHX\n",
      "Fetching data for FERG\n",
      "Fetching data for F\n",
      "Fetching data for IDXX\n",
      "No dividend data for IDXX\n",
      "Fetching data for TTWO\n",
      "Fetching data for TTD\n",
      "No dividend data for TTD\n",
      "Fetching data for VMC\n",
      "Fetching data for KDP\n",
      "Fetching data for MNST\n",
      "Fetching data for SYY\n",
      "Fetching data for ETR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not get exchangeTimezoneName for ticker 'ETR' reason: 'chart'\n",
      "$ETR: possibly delisted; no timezone found\n",
      "$ETR: possibly delisted; no price data found  (period=5y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No dividend data for ETR\n",
      "Fetching data for RBLX\n",
      "No dividend data for RBLX\n",
      "Fetching data for IQV\n",
      "No dividend data for IQV\n",
      "Fetching data for DXCM\n",
      "No dividend data for DXCM\n",
      "Fetching data for DD\n",
      "Fetching data for EA\n",
      "Fetching data for ARES\n",
      "Fetching data for IR\n",
      "Fetching data for VEEV\n",
      "No dividend data for VEEV\n",
      "Fetching data for UAL\n",
      "Fetching data for RMD\n",
      "Fetching data for CHTR\n",
      "No dividend data for CHTR\n",
      "Fetching data for ROK\n",
      "Fetching data for EBAY\n",
      "Fetching data for NDAQ\n",
      "Fetching data for MTB\n",
      "Fetching data for ALNY\n",
      "No dividend data for ALNY\n",
      "Fetching data for ED\n",
      "Fetching data for NUE\n",
      "Fetching data for GRMN\n",
      "Fetching data for HPQ\n",
      "Fetching data for GIS\n",
      "Fetching data for OXY\n",
      "Fetching data for HIG\n",
      "Fetching data for WTW\n",
      "Fetching data for PCG\n",
      "Fetching data for WEC\n",
      "Fetching data for EXR\n",
      "Fetching data for MLM\n",
      "Fetching data for KEYS\n",
      "No dividend data for KEYS\n",
      "Fetching data for MPWR\n",
      "Fetching data for WAB\n",
      "Fetching data for VICI\n",
      "Fetching data for ACGL\n",
      "Fetching data for USD\n",
      "Fetching data for EQT\n",
      "Fetching data for XYL\n",
      "Fetching data for DELL\n",
      "Fetching data for CVNA\n",
      "No dividend data for CVNA\n",
      "Fetching data for AVB\n",
      "Fetching data for TSCO\n",
      "Fetching data for CAH\n",
      "Fetching data for EFX\n",
      "Fetching data for HUM\n",
      "Fetching data for FITB\n",
      "Fetching data for CSGP\n",
      "No dividend data for CSGP\n",
      "Fetching data for FANG\n",
      "Fetching data for ANSS\n",
      "No dividend data for ANSS\n",
      "Fetching data for LEN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not get exchangeTimezoneName for ticker 'LEN' reason: 'chart'\n",
      "$LEN: possibly delisted; no timezone found\n",
      "$LEN: possibly delisted; no price data found  (period=5y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No dividend data for LEN\n",
      "Fetching data for MCHP\n",
      "Fetching data for IP\n",
      "Fetching data for RJF\n",
      "Fetching data for CPNG\n",
      "No dividend data for CPNG\n",
      "Fetching data for STT\n",
      "Fetching data for CNC\n",
      "No dividend data for CNC\n",
      "Fetching data for FTV\n",
      "Fetching data for HPE\n",
      "Fetching data for BR\n",
      "Fetching data for VTR\n",
      "Fetching data for IRM\n",
      "Fetching data for SW\n",
      "Fetching data for LPLA\n",
      "Fetching data for DOV\n",
      "Fetching data for PPG\n",
      "Fetching data for WSM\n",
      "Fetching data for GPN\n",
      "Fetching data for DOW\n",
      "Fetching data for TYL\n",
      "Fetching data for CCL\n",
      "Fetching data for EQR\n",
      "Fetching data for MTD\n",
      "No dividend data for MTD\n",
      "Fetching data for DTE\n",
      "Fetching data for BRO\n",
      "Fetching data for AEE\n",
      "Fetching data for STZ\n",
      "Fetching data for GDDY\n",
      "No dividend data for GDDY\n",
      "Fetching data for TPL\n",
      "Fetching data for CPAY\n",
      "No dividend data for CPAY\n",
      "Fetching data for CHD\n",
      "Fetching data for KHC\n",
      "Fetching data for SYF\n",
      "Fetching data for EXPE\n",
      "Fetching data for FCNCA\n",
      "Fetching data for CDW\n",
      "Fetching data for WBD\n",
      "No dividend data for WBD\n",
      "Fetching data for PPL\n",
      "Fetching data for NTAP\n",
      "Fetching data for IBKR\n",
      "Fetching data for LYV\n",
      "No dividend data for LYV\n",
      "Fetching data for AWK\n",
      "Fetching data for EXE\n",
      "Fetching data for DKNG\n",
      "No dividend data for DKNG\n",
      "Fetching data for HBAN\n",
      "Fetching data for VLTO\n",
      "Fetching data for MKL\n",
      "No dividend data for MKL\n",
      "Fetching data for SMCI\n",
      "No dividend data for SMCI\n",
      "Fetching data for WDC\n",
      "Fetching data for DECK\n",
      "No dividend data for DECK\n",
      "Fetching data for TROW\n",
      "Fetching data for PINS\n",
      "No dividend data for PINS\n",
      "Fetching data for HAL\n",
      "Fetching data for FE\n",
      "Fetching data for HSY\n",
      "Fetching data for DRI\n",
      "Fetching data for ATO\n",
      "Fetching data for TDY\n",
      "No dividend data for TDY\n",
      "Fetching data for ZM\n",
      "No dividend data for ZM\n",
      "Fetching data for NRG\n",
      "Fetching data for RF\n",
      "Fetching data for ON\n",
      "No dividend data for ON\n",
      "Fetching data for SBAC\n",
      "Fetching data for PHM\n",
      "Fetching data for ES\n",
      "Fetching data for ADM\n",
      "Fetching data for NTRS\n",
      "Fetching data for IFF\n",
      "Fetching data for WAT\n",
      "No dividend data for WAT\n",
      "Fetching data for DVN\n",
      "Fetching data for STE\n",
      "Fetching data for K\n",
      "Fetching data for CNP\n",
      "Fetching data for WY\n",
      "Fetching data for CBOE\n",
      "Fetching data for NVR\n",
      "Fetching data for CINF\n",
      "Fetching data for HUBB\n",
      "Fetching data for AFRM\n",
      "No dividend data for AFRM\n",
      "Fetching data for MDB\n",
      "No dividend data for MDB\n",
      "Fetching data for PSTG\n",
      "No dividend data for PSTG\n",
      "Fetching data for CFG\n",
      "Fetching data for FWONK\n",
      "No dividend data for FWONK\n",
      "Fetching data for LH\n",
      "Fetching data for CMS\n",
      "Fetching data for TPR\n",
      "Fetching data for CTRA\n",
      "Fetching data for PTC\n",
      "No dividend data for PTC\n",
      "Fetching data for STLD\n",
      "Fetching data for BIIB\n",
      "No dividend data for BIIB\n",
      "Fetching data for NTRA\n",
      "No dividend data for NTRA\n",
      "Fetching data for LYB\n",
      "Fetching data for ZBH\n",
      "Fetching data for ZS\n",
      "No dividend data for ZS\n",
      "Fetching data for EME\n",
      "Fetching data for LII\n",
      "Fetching data for PODD\n",
      "No dividend data for PODD\n",
      "Fetching data for PFG\n",
      "Fetching data for BBY\n",
      "Fetching data for MKC\n",
      "Fetching data for VRSN\n",
      "Fetching data for TRU\n",
      "Fetching data for TWLO\n",
      "No dividend data for TWLO\n",
      "Fetching data for INVH\n",
      "Fetching data for EIX\n",
      "Fetching data for SSNC\n",
      "Fetching data for JBL\n",
      "Fetching data for PKG\n",
      "Fetching data for DGX\n",
      "Fetching data for NI\n",
      "Fetching data for ESS\n",
      "Fetching data for MAA\n",
      "Fetching data for TOST\n",
      "No dividend data for TOST\n",
      "Fetching data for CLX\n",
      "Fetching data for FFIV\n",
      "No dividend data for FFIV\n",
      "Fetching data for EQH\n",
      "Fetching data for LUV\n",
      "Fetching data for DT\n",
      "No dividend data for DT\n",
      "Fetching data for TRMB\n",
      "No dividend data for TRMB\n",
      "Fetching data for DOCU\n",
      "No dividend data for DOCU\n",
      "Fetching data for LDOS\n",
      "Fetching data for WRB\n",
      "Fetching data for TER\n",
      "Fetching data for RBA\n",
      "Fetching data for BLDR\n",
      "No dividend data for BLDR\n",
      "Fetching data for NTNX\n",
      "No dividend data for NTNX\n",
      "Fetching data for SNA\n",
      "Fetching data for GPC\n",
      "Fetching data for GWRE\n",
      "No dividend data for GWRE\n",
      "Fetching data for ULTA\n",
      "Fetching data for FDS\n",
      "Fetching data for MAS\n",
      "Fetching data for SOFI\n",
      "No dividend data for SOFI\n",
      "Fetching data for FSLR\n",
      "No dividend data for FSLR\n",
      "Fetching data for COO\n",
      "Fetching data for WSO\n",
      "Fetching data for DPZ\n",
      "Fetching data for ARE\n",
      "Fetching data for CSL\n",
      "Fetching data for XPO\n",
      "No dividend data for XPO\n",
      "Fetching data for USFD\n",
      "No dividend data for USFD\n",
      "Fetching data for KEY\n",
      "Fetching data for TSN\n",
      "Fetching data for ZBRA\n",
      "No dividend data for ZBRA\n",
      "Fetching data for J\n",
      "Fetching data for UTHR\n",
      "No dividend data for UTHR\n",
      "Fetching data for PNR\n",
      "Fetching data for ENTG\n",
      "Fetching data for RS\n",
      "Fetching data for ILMN\n",
      "No dividend data for ILMN\n",
      "Fetching data for EXPD\n",
      "Fetching data for CASY\n",
      "Fetching data for DG\n",
      "Fetching data for OMC\n",
      "Fetching data for EL\n",
      "Fetching data for MOH\n",
      "No dividend data for MOH\n",
      "Fetching data for DUOL\n",
      "No dividend data for DUOL\n",
      "Fetching data for APTV\n",
      "Fetching data for LNT\n",
      "Fetching data for BAX\n",
      "Fetching data for RPM\n",
      "Fetching data for WST\n",
      "Fetching data for BURL\n",
      "No dividend data for BURL\n",
      "Fetching data for ALGN\n",
      "No dividend data for ALGN\n",
      "Fetching data for OC\n",
      "Fetching data for OKTA\n",
      "No dividend data for OKTA\n",
      "Fetching data for SUI\n",
      "Fetching data for LVS\n",
      "Fetching data for FNF\n",
      "Fetching data for BAH\n",
      "Fetching data for GEN\n",
      "Fetching data for AKAM\n",
      "No dividend data for AKAM\n",
      "Fetching data for IEX\n",
      "Fetching data for EVRG\n",
      "Fetching data for L\n",
      "Fetching data for TW\n",
      "Fetching data for EPAM\n",
      "No dividend data for EPAM\n",
      "Fetching data for BALL\n",
      "Fetching data for AMCR\n",
      "Fetching data for AVY\n",
      "Fetching data for HOLX\n",
      "No dividend data for HOLX\n",
      "Fetching data for DLTR\n",
      "No dividend data for DLTR\n",
      "Fetching data for KIM\n",
      "Fetching data for HEIA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$HEIA: possibly delisted; no timezone found\n",
      "$HEIA: possibly delisted; no price data found  (period=5y) (Yahoo error = \"No data found, symbol may be delisted\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No dividend data for HEIA\n",
      "Fetching data for EG\n",
      "Fetching data for CF\n",
      "Fetching data for GGG\n",
      "Fetching data for ROL\n",
      "Fetching data for UDR\n",
      "Fetching data for BJ\n",
      "No dividend data for BJ\n",
      "Fetching data for KMX\n",
      "No dividend data for KMX\n",
      "Fetching data for JBHT\n",
      "Fetching data for RVTY\n",
      "Fetching data for TKO\n",
      "Fetching data for EWBC\n",
      "Fetching data for FIX\n",
      "Fetching data for ACM\n",
      "Fetching data for JLL\n",
      "Fetching data for DOC\n",
      "Fetching data for DKS\n",
      "Fetching data for SWK\n",
      "Fetching data for TXT\n",
      "Fetching data for PFGC\n",
      "No dividend data for PFGC\n",
      "Fetching data for REG\n",
      "Fetching data for ITCI\n",
      "No dividend data for ITCI\n",
      "Fetching data for RGA\n",
      "Fetching data for VTRS\n",
      "Fetching data for UNM\n",
      "Fetching data for CIEN\n",
      "No dividend data for CIEN\n",
      "Fetching data for FTI\n",
      "Fetching data for POOL\n",
      "Fetching data for WPC\n",
      "Fetching data for SAIA\n",
      "No dividend data for SAIA\n",
      "Fetching data for Z\n",
      "No dividend data for Z\n",
      "Fetching data for FOXA\n",
      "Fetching data for RPRX\n",
      "Fetching data for THC\n",
      "Fetching data for ROKU\n",
      "No dividend data for ROKU\n",
      "Fetching data for TOL\n",
      "Fetching data for GLPI\n",
      "Fetching data for JEF\n",
      "Fetching data for CPT\n",
      "Fetching data for OWL\n",
      "Fetching data for ELS\n",
      "Fetching data for NDSN\n",
      "Fetching data for JKHY\n",
      "Fetching data for CW\n",
      "Fetching data for AVTR\n",
      "No dividend data for AVTR\n",
      "Fetching data for ITT\n",
      "Fetching data for BMRN\n",
      "No dividend data for BMRN\n",
      "Fetching data for CAG\n",
      "Fetching data for EMN\n",
      "Fetching data for LECO\n",
      "Fetching data for AMH\n",
      "Fetching data for NLY\n",
      "Fetching data for FHN\n",
      "Fetching data for CLH\n",
      "No dividend data for CLH\n",
      "Fetching data for JNPR\n",
      "Fetching data for TPX\n",
      "Fetching data for RNR\n",
      "Fetching data for MANH\n",
      "No dividend data for MANH\n",
      "Fetching data for ALLE\n",
      "Fetching data for RL\n",
      "Fetching data for NWSA\n",
      "Fetching data for RIVN\n",
      "No dividend data for RIVN\n",
      "Fetching data for HST\n",
      "Fetching data for CHRW\n",
      "Fetching data for LAMR\n",
      "Fetching data for AR\n",
      "No dividend data for AR\n",
      "Fetching data for NBIX\n",
      "No dividend data for NBIX\n",
      "Fetching data for OVV\n",
      "Fetching data for TXRH\n",
      "Fetching data for CG\n",
      "Fetching data for NCLH\n",
      "No dividend data for NCLH\n",
      "Fetching data for WWD\n",
      "Fetching data for INCY\n",
      "No dividend data for INCY\n",
      "Fetching data for NVT\n",
      "Fetching data for CNH\n",
      "Fetching data for SCI\n",
      "Fetching data for BXP\n",
      "Fetching data for SF\n",
      "Fetching data for SNX\n",
      "Fetching data for COHR\n",
      "No dividend data for COHR\n",
      "Fetching data for GL\n",
      "Fetching data for PAYC\n",
      "Fetching data for MRNA\n",
      "No dividend data for MRNA\n",
      "Fetching data for TAP\n",
      "Fetching data for GME\n",
      "Fetching data for SWKS\n",
      "Fetching data for ALLY\n",
      "Fetching data for AAL\n",
      "Fetching data for UHS\n",
      "Fetching data for AIZ\n",
      "Fetching data for SJM\n",
      "Fetching data for CNM\n",
      "No dividend data for CNM\n",
      "Fetching data for BLD\n",
      "No dividend data for BLD\n",
      "Fetching data for FND\n",
      "No dividend data for FND\n",
      "Fetching data for RBC\n",
      "Fetching data for CCK\n",
      "Fetching data for SOLV\n",
      "No dividend data for SOLV\n",
      "Fetching data for LKQ\n",
      "Fetching data for DOX\n",
      "Fetching data for IPG\n",
      "Fetching data for WBS\n",
      "Fetching data for AYI\n",
      "Fetching data for LAD\n",
      "Fetching data for TECH\n",
      "Fetching data for PNW\n",
      "Fetching data for PEN\n",
      "No dividend data for PEN\n",
      "Fetching data for EXEL\n",
      "No dividend data for EXEL\n",
      "Fetching data for DAY\n",
      "No dividend data for DAY\n",
      "Fetching data for BRBR\n",
      "No dividend data for BRBR\n",
      "Fetching data for BG\n",
      "Fetching data for ARMK\n",
      "Fetching data for CAVA\n",
      "No dividend data for CAVA\n",
      "Fetching data for EHC\n",
      "Fetching data for ESTC\n",
      "No dividend data for ESTC\n",
      "Fetching data for HSIC\n",
      "No dividend data for HSIC\n",
      "Fetching data for OHI\n",
      "Fetching data for SRPT\n",
      "No dividend data for SRPT\n",
      "Fetching data for KNSL\n",
      "Fetching data for HEI\n",
      "Fetching data for EVR\n",
      "Fetching data for BWXT\n",
      "Fetching data for ALK\n",
      "Fetching data for DTM\n",
      "Fetching data for PRI\n",
      "Fetching data for ATR\n",
      "Fetching data for G\n",
      "Fetching data for RGLD\n",
      "Fetching data for KD\n",
      "No dividend data for KD\n",
      "Fetching data for ALAB\n",
      "No dividend data for ALAB\n",
      "Fetching data for PCTY\n",
      "No dividend data for PCTY\n",
      "Fetching data for ALB\n",
      "Fetching data for DOCS\n",
      "No dividend data for DOCS\n",
      "Fetching data for WAL\n",
      "Fetching data for GMED\n",
      "No dividend data for GMED\n",
      "Fetching data for GLOB\n",
      "No dividend data for GLOB\n",
      "Fetching data for MGM\n",
      "Fetching data for PR\n",
      "Fetching data for HLI\n",
      "Fetching data for CUBE\n",
      "Fetching data for PCOR\n",
      "No dividend data for PCOR\n",
      "Fetching data for WYNN\n",
      "Fetching data for ALSN\n",
      "Fetching data for MUSA\n",
      "Fetching data for RRX\n",
      "Fetching data for WING\n",
      "Fetching data for RRC\n",
      "Fetching data for ORI\n",
      "Fetching data for VFC\n",
      "Fetching data for EXAS\n",
      "No dividend data for EXAS\n",
      "Fetching data for AA\n",
      "Fetching data for BROS\n",
      "No dividend data for BROS\n",
      "Fetching data for LBRDK\n",
      "No dividend data for LBRDK\n",
      "Fetching data for PNFP\n",
      "Fetching data for FRT\n",
      "Fetching data for EGP\n",
      "Fetching data for MTCH\n",
      "Fetching data for WMS\n",
      "Fetching data for MIDD\n",
      "Fetching data for WTRG\n",
      "Fetching data for REXR\n",
      "Fetching data for AFG\n",
      "Fetching data for LSCC\n",
      "No dividend data for LSCC\n",
      "Fetching data for CFLT\n",
      "No dividend data for CFLT\n",
      "Fetching data for CMA\n",
      "Fetching data for PLNT\n",
      "Fetching data for CART\n",
      "No dividend data for CART\n",
      "Fetching data for MORN\n",
      "Fetching data for LNW\n",
      "No dividend data for LNW\n",
      "Fetching data for GNRC\n",
      "Fetching data for COKE\n",
      "Fetching data for WCC\n",
      "Fetching data for FYBR\n",
      "No dividend data for FYBR\n",
      "Fetching data for ACI\n",
      "Fetching data for ONTO\n",
      "No dividend data for ONTO\n",
      "Fetching data for MEDP\n",
      "No dividend data for MEDP\n",
      "Fetching data for WTFC\n",
      "Fetching data for CZR\n",
      "No dividend data for CZR\n",
      "Fetching data for X\n",
      "Fetching data for QGEN\n",
      "Fetching data for SCCO\n",
      "Fetching data for OGE\n",
      "Fetching data for APG\n",
      "No dividend data for APG\n",
      "Fetching data for AGNC\n",
      "Fetching data for FBIN\n",
      "Fetching data for CHDN\n",
      "Fetching data for MOS\n",
      "Fetching data for HAS\n",
      "Fetching data for APA\n",
      "Fetching data for CFR\n",
      "Fetching data for ENPH\n",
      "No dividend data for ENPH\n",
      "Fetching data for GTLB\n",
      "No dividend data for GTLB\n",
      "Fetching data for MTZ\n",
      "No dividend data for MTZ\n",
      "Fetching data for SEIC\n",
      "Fetching data for KNX\n",
      "Fetching data for TTC\n",
      "Fetching data for LW\n",
      "Fetching data for SKX\n",
      "No dividend data for SKX\n",
      "Fetching data for NYT\n",
      "Fetching data for HRL\n",
      "Fetching data for CHE\n",
      "Fetching data for JAZZ\n",
      "No dividend data for JAZZ\n",
      "Fetching data for EXP\n",
      "Fetching data for CR\n",
      "Fetching data for BBWI\n",
      "Fetching data for DCI\n",
      "Fetching data for WH\n",
      "Fetching data for FLS\n",
      "Fetching data for RGEN\n",
      "No dividend data for RGEN\n",
      "Fetching data for CBSH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not get exchangeTimezoneName for ticker 'CBSH' reason: 'chart'\n",
      "$CBSH: possibly delisted; no timezone found\n",
      "$CBSH: possibly delisted; no price data found  (period=5y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No dividend data for CBSH\n",
      "Fetching data for ZION\n",
      "Fetching data for INGR\n",
      "Fetching data for BERY\n",
      "Fetching data for BRX\n",
      "Fetching data for AXTA\n",
      "No dividend data for AXTA\n",
      "Fetching data for TTEK\n",
      "Fetching data for AOS\n",
      "Fetching data for TFX\n",
      "Fetching data for DVA\n",
      "No dividend data for DVA\n",
      "Fetching data for GPK\n",
      "Fetching data for DBX\n",
      "No dividend data for DBX\n",
      "Fetching data for SNV\n",
      "Fetching data for FOUR\n",
      "No dividend data for FOUR\n",
      "Fetching data for MASI\n",
      "Fetching data for CRL\n",
      "No dividend data for CRL\n",
      "Fetching data for AAON\n",
      "Fetching data for VOYA\n",
      "Fetching data for ADC\n",
      "Fetching data for VNO\n",
      "Fetching data for ATI\n",
      "Fetching data for CPB\n",
      "Fetching data for NNN\n",
      "Fetching data for MAT\n",
      "Fetching data for CACI\n",
      "No dividend data for CACI\n",
      "Fetching data for CE\n",
      "Fetching data for SSD\n",
      "Fetching data for TREX\n",
      "No dividend data for TREX\n",
      "Fetching data for FR\n",
      "Fetching data for BFAM\n",
      "No dividend data for BFAM\n",
      "Fetching data for QRVO\n",
      "No dividend data for QRVO\n",
      "Fetching data for ESAB\n",
      "Fetching data for HRB\n",
      "Fetching data for SN\n",
      "Fetching data for BPOP\n",
      "Fetching data for AZEK\n",
      "No dividend data for AZEK\n",
      "Fetching data for MKTX\n",
      "Fetching data for LPX\n",
      "Fetching data for WSC\n",
      "No dividend data for WSC\n",
      "Fetching data for PB\n",
      "Fetching data for RYAN\n",
      "Fetching data for R\n",
      "Fetching data for AZPN\n",
      "No dividend data for AZPN\n",
      "Fetching data for AES\n",
      "Fetching data for BWA\n",
      "Fetching data for FOX\n",
      "Fetching data for WBA\n",
      "Fetching data for OSK\n",
      "Fetching data for AXS\n",
      "Fetching data for LNC\n",
      "Fetching data for CHRD\n",
      "Fetching data for MTSI\n",
      "No dividend data for MTSI\n",
      "Fetching data for S\n",
      "No dividend data for S\n",
      "Fetching data for MKSI\n",
      "Fetching data for IVZ\n",
      "Fetching data for KBR\n",
      "Fetching data for UGI\n",
      "Fetching data for MTDR\n",
      "Fetching data for MTG\n",
      "Fetching data for PATH\n",
      "No dividend data for PATH\n",
      "Fetching data for SITE\n",
      "No dividend data for SITE\n",
      "Fetching data for UHALB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$UHALB: possibly delisted; no timezone found\n",
      "$UHALB: possibly delisted; no price data found  (period=5y) (Yahoo error = \"No data found, symbol may be delisted\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No dividend data for UHALB\n",
      "Fetching data for ETSY\n",
      "No dividend data for ETSY\n",
      "Fetching data for SLM\n",
      "Fetching data for BSY\n",
      "Fetching data for OMF\n",
      "Fetching data for OLED\n",
      "Fetching data for FCN\n",
      "No dividend data for FCN\n",
      "Fetching data for AWI\n",
      "Fetching data for CROX\n",
      "No dividend data for CROX\n",
      "Fetching data for PARA\n",
      "Fetching data for WEX\n",
      "No dividend data for WEX\n",
      "Fetching data for STAG\n",
      "Fetching data for OLLI\n",
      "No dividend data for OLLI\n",
      "Fetching data for FAF\n",
      "Fetching data for DAR\n",
      "No dividend data for DAR\n",
      "Fetching data for NFG\n",
      "Fetching data for KEX\n",
      "Fetching data for RLI\n",
      "Fetching data for STWD\n",
      "Fetching data for VNOM\n",
      "Fetching data for MHK\n",
      "No dividend data for MHK\n",
      "Fetching data for MTN\n",
      "Fetching data for U\n",
      "No dividend data for U\n",
      "Fetching data for H\n",
      "Fetching data for VMI\n",
      "Fetching data for HII\n",
      "Fetching data for AGCO\n",
      "Fetching data for NOV\n",
      "Fetching data for RHI\n",
      "Fetching data for HR\n",
      "Fetching data for RITM\n",
      "Fetching data for DINO\n",
      "Fetching data for BILL\n",
      "No dividend data for BILL\n",
      "Fetching data for COLD\n",
      "Fetching data for VNT\n",
      "Fetching data for FRPT\n",
      "No dividend data for FRPT\n",
      "Fetching data for LAZ\n",
      "Fetching data for XP\n",
      "Fetching data for MSA\n",
      "Fetching data for LFUS\n",
      "Fetching data for ESI\n",
      "Fetching data for CRUS\n",
      "No dividend data for CRUS\n",
      "Fetching data for IDA\n",
      "Fetching data for BEN\n",
      "Fetching data for THG\n",
      "Fetching data for SIRI\n",
      "Fetching data for ARW\n",
      "Fetching data for LSTR\n",
      "Fetching data for CGNX\n",
      "Fetching data for CLF\n",
      "Fetching data for GNTX\n",
      "Fetching data for COLB\n",
      "Fetching data for POST\n",
      "No dividend data for POST\n",
      "Fetching data for JHG\n",
      "Fetching data for AM\n",
      "Fetching data for FNB\n",
      "Fetching data for RH\n",
      "No dividend data for RH\n",
      "Fetching data for WHR\n",
      "Fetching data for TKR\n",
      "Fetching data for INSP\n",
      "No dividend data for INSP\n",
      "Fetching data for ELAN\n",
      "No dividend data for ELAN\n",
      "Fetching data for HXL\n",
      "Fetching data for BRKR\n",
      "Fetching data for OZK\n",
      "Fetching data for AMG\n",
      "Fetching data for THO\n",
      "Fetching data for SGAFT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SGAFT: possibly delisted; no timezone found\n",
      "$SGAFT: possibly delisted; no price data found  (period=5y) (Yahoo error = \"No data found, symbol may be delisted\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No dividend data for SGAFT\n",
      "Fetching data for LOPE\n",
      "No dividend data for LOPE\n",
      "Fetching data for BFB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BFB: possibly delisted; no timezone found\n",
      "$BFB: possibly delisted; no price data found  (period=5y) (Yahoo error = \"No data found, symbol may be delisted\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No dividend data for BFB\n",
      "Fetching data for LEA\n",
      "Fetching data for BYD\n",
      "Fetching data for GTES\n",
      "No dividend data for GTES\n",
      "Fetching data for BIO\n",
      "No dividend data for BIO\n",
      "Fetching data for LITE\n",
      "No dividend data for LITE\n",
      "Fetching data for SAIC\n",
      "Fetching data for VVV\n",
      "Fetching data for WFRD\n",
      "Fetching data for AL\n",
      "Fetching data for APPF\n",
      "No dividend data for APPF\n",
      "Fetching data for CIVI\n",
      "Fetching data for SEE\n",
      "Fetching data for TPG\n",
      "Fetching data for NXST\n",
      "Fetching data for AN\n",
      "Fetching data for HCP\n",
      "No dividend data for HCP\n",
      "Fetching data for FIVE\n",
      "No dividend data for FIVE\n",
      "Fetching data for SON\n",
      "Fetching data for IONS\n",
      "No dividend data for IONS\n",
      "Fetching data for DLB\n",
      "Fetching data for CCCS\n",
      "No dividend data for CCCS\n",
      "Fetching data for W\n",
      "No dividend data for W\n",
      "Fetching data for LYFT\n",
      "No dividend data for LYFT\n",
      "Fetching data for WTM\n",
      "Fetching data for SLGN\n",
      "Fetching data for EEFT\n",
      "No dividend data for EEFT\n",
      "Fetching data for AGO\n",
      "Fetching data for BC\n",
      "Fetching data for CUZ\n",
      "Fetching data for GXO\n",
      "No dividend data for GXO\n",
      "Fetching data for FMC\n",
      "Fetching data for ROIV\n",
      "No dividend data for ROIV\n",
      "Fetching data for ST\n",
      "Fetching data for GAP\n",
      "Fetching data for AVT\n",
      "Fetching data for GFS\n",
      "No dividend data for GFS\n",
      "Fetching data for KMPR\n",
      "Fetching data for PVH\n",
      "Fetching data for CHH\n",
      "Fetching data for M\n",
      "Fetching data for SPR\n",
      "Fetching data for NWS\n",
      "Fetching data for OGN\n",
      "Fetching data for BHF\n",
      "No dividend data for BHF\n",
      "Fetching data for KRC\n",
      "Fetching data for MSGS\n",
      "Fetching data for CELH\n",
      "No dividend data for CELH\n",
      "Fetching data for PEGA\n",
      "Fetching data for RYN\n",
      "Fetching data for ELF\n",
      "No dividend data for ELF\n",
      "Fetching data for MSM\n",
      "Fetching data for TNL\n",
      "Fetching data for WLK\n",
      "Fetching data for ACHC\n",
      "No dividend data for ACHC\n",
      "Fetching data for LLYVK\n",
      "No dividend data for LLYVK\n",
      "Fetching data for NEU\n",
      "Fetching data for RARE\n",
      "No dividend data for RARE\n",
      "Fetching data for XRAY\n",
      "Fetching data for BEPC\n",
      "Fetching data for DXC\n",
      "Fetching data for ZG\n",
      "No dividend data for ZG\n",
      "Fetching data for NVST\n",
      "No dividend data for NVST\n",
      "Fetching data for PENN\n",
      "No dividend data for PENN\n",
      "Fetching data for IRDM\n",
      "Fetching data for EPR\n",
      "Fetching data for LINE\n",
      "Fetching data for MDU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not get exchangeTimezoneName for ticker 'MDU' reason: 'chart'\n",
      "$MDU: possibly delisted; no timezone found\n",
      "$MDU: possibly delisted; no price data found  (period=5y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No dividend data for MDU\n",
      "Fetching data for FHB\n",
      "Fetching data for IAC\n",
      "Fetching data for FLO\n",
      "Fetching data for PSN\n",
      "No dividend data for PSN\n",
      "Fetching data for PRGO\n",
      "Fetching data for LCID\n",
      "No dividend data for LCID\n",
      "Fetching data for YETI\n",
      "No dividend data for YETI\n",
      "Fetching data for ASH\n",
      "Fetching data for HOG\n",
      "Fetching data for DNB\n",
      "Fetching data for VKTX\n",
      "No dividend data for VKTX\n",
      "Fetching data for CACC\n",
      "No dividend data for CACC\n",
      "Fetching data for OLN\n",
      "Fetching data for ZI\n",
      "No dividend data for ZI\n",
      "Fetching data for ALGM\n",
      "No dividend data for ALGM\n",
      "Fetching data for HIW\n",
      "Fetching data for MP\n",
      "No dividend data for MP\n",
      "Fetching data for VAC\n",
      "Fetching data for VIRT\n",
      "Fetching data for PAG\n",
      "Fetching data for DV\n",
      "No dividend data for DV\n",
      "Fetching data for WU\n",
      "Fetching data for MRP\n",
      "No dividend data for MRP\n",
      "Fetching data for COLM\n",
      "Fetching data for NWL\n",
      "Fetching data for AMED\n",
      "No dividend data for AMED\n",
      "Fetching data for SMG\n",
      "Fetching data for CXT\n",
      "Fetching data for MPW\n",
      "Fetching data for RNG\n",
      "No dividend data for RNG\n",
      "Fetching data for AAP\n",
      "Fetching data for FIVN\n",
      "No dividend data for FIVN\n",
      "Fetching data for HUN\n",
      "Fetching data for APLS\n",
      "No dividend data for APLS\n",
      "Fetching data for NCNO\n",
      "No dividend data for NCNO\n",
      "Fetching data for PK\n",
      "Fetching data for MAN\n",
      "Fetching data for CPRI\n",
      "No dividend data for CPRI\n",
      "Fetching data for NSA\n",
      "Fetching data for AMKR\n",
      "Fetching data for QDEL\n",
      "No dividend data for QDEL\n",
      "Fetching data for WEN\n",
      "Fetching data for TDC\n",
      "No dividend data for TDC\n",
      "Fetching data for BOKF\n",
      "Fetching data for AZTA\n",
      "Fetching data for AMTM\n",
      "No dividend data for AMTM\n",
      "Fetching data for ECG\n",
      "No dividend data for ECG\n",
      "Fetching data for HHH\n",
      "No dividend data for HHH\n",
      "Fetching data for CC\n",
      "Fetching data for ENOV\n",
      "No dividend data for ENOV\n",
      "Fetching data for JWN\n",
      "Fetching data for ADT\n",
      "Fetching data for PII\n",
      "Fetching data for DJT\n",
      "No dividend data for DJT\n",
      "Fetching data for CNXC\n",
      "Fetching data for CWEN\n",
      "Fetching data for COTY\n",
      "Fetching data for BIRK\n",
      "No dividend data for BIRK\n",
      "Fetching data for SAM\n",
      "No dividend data for SAM\n",
      "Fetching data for PPC\n",
      "Fetching data for SPB\n",
      "Fetching data for HAYW\n",
      "No dividend data for HAYW\n",
      "Fetching data for LOAR\n",
      "No dividend data for LOAR\n",
      "Fetching data for SHC\n",
      "Failed to fetch data for SHC\n",
      "Fetching data for CLVT\n",
      "Failed to fetch data for CLVT\n",
      "Fetching data for CRI\n",
      "Failed to fetch data for CRI\n",
      "Fetching data for FWONA\n",
      "Failed to fetch data for FWONA\n",
      "Fetching data for LBTYK\n",
      "Failed to fetch data for LBTYK\n",
      "Fetching data for VSTS\n",
      "Failed to fetch data for VSTS\n",
      "Fetching data for PYCR\n",
      "Failed to fetch data for PYCR\n",
      "Fetching data for IPGP\n",
      "Failed to fetch data for IPGP\n",
      "Fetching data for TRIP\n",
      "Failed to fetch data for TRIP\n",
      "Fetching data for SARO\n",
      "Failed to fetch data for SARO\n",
      "Fetching data for QS\n",
      "Failed to fetch data for QS\n",
      "Fetching data for PINC\n",
      "Failed to fetch data for PINC\n",
      "Fetching data for LBTYA\n",
      "Failed to fetch data for LBTYA\n",
      "Fetching data for RKT\n",
      "Failed to fetch data for RKT\n",
      "Fetching data for AS\n",
      "Failed to fetch data for AS\n",
      "Fetching data for CERT\n",
      "Failed to fetch data for CERT\n",
      "Fetching data for CAR\n",
      "Failed to fetch data for CAR\n",
      "Fetching data for INFA\n",
      "Failed to fetch data for INFA\n",
      "Fetching data for GO\n",
      "Failed to fetch data for GO\n",
      "Fetching data for BFA\n",
      "Failed to fetch data for BFA\n",
      "Fetching data for LLYVA\n",
      "Failed to fetch data for LLYVA\n",
      "Fetching data for GRAL\n",
      "Failed to fetch data for GRAL\n",
      "Fetching data for DDS\n",
      "Failed to fetch data for DDS\n",
      "Fetching data for UI\n",
      "Failed to fetch data for UI\n",
      "Fetching data for LEG\n",
      "Failed to fetch data for LEG\n",
      "Fetching data for UAA\n",
      "Failed to fetch data for UAA\n",
      "Fetching data for LENB\n",
      "Failed to fetch data for LENB\n",
      "Fetching data for FTRE\n",
      "Failed to fetch data for FTRE\n",
      "Fetching data for LBRDA\n",
      "Failed to fetch data for LBRDA\n",
      "Fetching data for TXG\n",
      "Failed to fetch data for TXG\n",
      "Fetching data for UA\n",
      "Failed to fetch data for UA\n",
      "Fetching data for KSS\n",
      "Failed to fetch data for KSS\n",
      "Fetching data for SNDR\n",
      "Failed to fetch data for SNDR\n",
      "Fetching data for REYN\n",
      "Failed to fetch data for REYN\n",
      "Fetching data for CNA\n",
      "Failed to fetch data for CNA\n",
      "Fetching data for CWENA\n",
      "Failed to fetch data for CWENA\n",
      "Fetching data for TFSL\n",
      "Failed to fetch data for TFSL\n",
      "Fetching data for NFE\n",
      "Failed to fetch data for NFE\n",
      "Fetching data for WOLF\n",
      "Failed to fetch data for WOLF\n",
      "Fetching data for UHAL\n",
      "Failed to fetch data for UHAL\n",
      "Fetching data for SEB\n",
      "Failed to fetch data for SEB\n",
      "Fetching data for UWMC\n",
      "Failed to fetch data for UWMC\n",
      "Fetching data for PLTK\n",
      "Failed to fetch data for PLTK\n",
      "Fetching data for INGM\n",
      "Failed to fetch data for INGM\n",
      "Fetching data for PARAA\n",
      "Failed to fetch data for PARAA\n",
      "Fetching data for SEG\n",
      "Failed to fetch data for SEG\n",
      "Fetching data for --\n",
      "Failed to fetch data for --\n",
      "Fetching data for FAH5\n",
      "Failed to fetch data for FAH5\n",
      "Fetching data for ESH5\n",
      "Failed to fetch data for ESH5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7871/335246469.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result = pd.concat(all_dividends, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Dividend</th>\n",
       "      <th>Stock Price</th>\n",
       "      <th>Dividend Yield (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1962-01-16 00:00:00-05:00</td>\n",
       "      <td>PG</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1962-01-16 00:00:00-05:00</td>\n",
       "      <td>CAT</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1962-01-23 00:00:00-05:00</td>\n",
       "      <td>KR</td>\n",
       "      <td>0.008594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1962-01-30 00:00:00-05:00</td>\n",
       "      <td>ED</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1962-01-31 00:00:00-05:00</td>\n",
       "      <td>CVX</td>\n",
       "      <td>0.029762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date Ticker  Dividend  Stock Price  Dividend Yield (%)\n",
       "0 1962-01-16 00:00:00-05:00     PG  0.005859          NaN                 NaN\n",
       "1 1962-01-16 00:00:00-05:00    CAT  0.010417          NaN                 NaN\n",
       "2 1962-01-23 00:00:00-05:00     KR  0.008594          NaN                 NaN\n",
       "3 1962-01-30 00:00:00-05:00     ED  0.093750          NaN                 NaN\n",
       "4 1962-01-31 00:00:00-05:00    CVX  0.029762          NaN                 NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the dividend data for the above stocks\n",
    "\n",
    "\n",
    "def get_dividend_data(tickers):\n",
    "    \"\"\"\n",
    "    Fetches dividend data and calculates dividend yield for a list of tickers over the past 5 years.\n",
    "\n",
    "    Parameters:\n",
    "    tickers (list): List of stock tickers.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with columns 'Date', 'Ticker', 'Dividend', 'Stock Price', and 'Dividend Yield (%)'.\n",
    "    \"\"\"\n",
    "    all_dividends = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        print(f\"Fetching data for {ticker}\")\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            dividends = stock.dividends\n",
    "            stock_prices = stock.history(period=\"5y\")['Close']  # Get past 5 years of stock price data\n",
    "        except:\n",
    "            print(f\"Failed to fetch data for {ticker}\")\n",
    "            continue\n",
    "\n",
    "        if dividends.empty:\n",
    "            print(f\"No dividend data for {ticker}\")\n",
    "            continue\n",
    "\n",
    "        # Create a dataframe for dividends\n",
    "        df = pd.DataFrame({\n",
    "            'Date': dividends.index,\n",
    "            'Ticker': ticker,\n",
    "            'Dividend': dividends.values\n",
    "        })\n",
    "\n",
    "        # Fetch stock price at the closest available date before or on dividend date\n",
    "        df['Stock Price'] = df['Date'].apply(lambda x: stock_prices.loc[:x].iloc[-2] if len(stock_prices.loc[:x]) > 1 else None)\n",
    "\n",
    "        # Calculate Dividend Yield (%)\n",
    "        df['Dividend Yield (%)'] = (df['Dividend'] / df['Stock Price']) * 100\n",
    "\n",
    "        all_dividends.append(df)\n",
    "\n",
    "    if all_dividends:\n",
    "        result = pd.concat(all_dividends, ignore_index=True)\n",
    "        result.sort_values(by='Date', inplace=True)\n",
    "        return result.reset_index(drop=True)\n",
    "    else:\n",
    "        print(\"No dividends found for any ticker.\")\n",
    "        return pd.DataFrame(columns=['Date', 'Ticker', 'Dividend', 'Stock Price', 'Dividend Yield (%)'])\n",
    "\n",
    "# Example usage:\n",
    "#tickers = stocks['symbol'].to_list()\n",
    "df = get_dividend_data(russel_tick)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9e074fd-6dbe-40a8-9b7d-1bb93b8e406e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Dividend</th>\n",
       "      <th>Stock Price</th>\n",
       "      <th>Dividend Yield (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69160</th>\n",
       "      <td>2025-02-13 00:00:00-05:00</td>\n",
       "      <td>RMD</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>236.070007</td>\n",
       "      <td>0.224510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69159</th>\n",
       "      <td>2025-02-13 00:00:00-05:00</td>\n",
       "      <td>DCI</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>69.550003</td>\n",
       "      <td>0.388210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69158</th>\n",
       "      <td>2025-02-13 00:00:00-05:00</td>\n",
       "      <td>TJX</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>124.035004</td>\n",
       "      <td>0.302334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69157</th>\n",
       "      <td>2025-02-13 00:00:00-05:00</td>\n",
       "      <td>ZION</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>55.040001</td>\n",
       "      <td>0.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69152</th>\n",
       "      <td>2025-02-12 00:00:00-05:00</td>\n",
       "      <td>NXST</td>\n",
       "      <td>1.860000</td>\n",
       "      <td>151.199997</td>\n",
       "      <td>1.230159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56653</th>\n",
       "      <td>2020-02-19 00:00:00-05:00</td>\n",
       "      <td>EXC</td>\n",
       "      <td>0.273181</td>\n",
       "      <td>30.052973</td>\n",
       "      <td>0.908998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56651</th>\n",
       "      <td>2020-02-19 00:00:00-05:00</td>\n",
       "      <td>LFUS</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>177.092285</td>\n",
       "      <td>0.271045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56655</th>\n",
       "      <td>2020-02-19 00:00:00-05:00</td>\n",
       "      <td>CNP</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>23.579014</td>\n",
       "      <td>1.229907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56656</th>\n",
       "      <td>2020-02-19 00:00:00-05:00</td>\n",
       "      <td>DAL</td>\n",
       "      <td>0.403000</td>\n",
       "      <td>57.414345</td>\n",
       "      <td>0.701915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56650</th>\n",
       "      <td>2020-02-19 00:00:00-05:00</td>\n",
       "      <td>CSL</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>153.616913</td>\n",
       "      <td>0.325485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12511 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Date Ticker  Dividend  Stock Price  \\\n",
       "69160 2025-02-13 00:00:00-05:00    RMD  0.530000   236.070007   \n",
       "69159 2025-02-13 00:00:00-05:00    DCI  0.270000    69.550003   \n",
       "69158 2025-02-13 00:00:00-05:00    TJX  0.375000   124.035004   \n",
       "69157 2025-02-13 00:00:00-05:00   ZION  0.430000    55.040001   \n",
       "69152 2025-02-12 00:00:00-05:00   NXST  1.860000   151.199997   \n",
       "...                         ...    ...       ...          ...   \n",
       "56653 2020-02-19 00:00:00-05:00    EXC  0.273181    30.052973   \n",
       "56651 2020-02-19 00:00:00-05:00   LFUS  0.480000   177.092285   \n",
       "56655 2020-02-19 00:00:00-05:00    CNP  0.290000    23.579014   \n",
       "56656 2020-02-19 00:00:00-05:00    DAL  0.403000    57.414345   \n",
       "56650 2020-02-19 00:00:00-05:00    CSL  0.500000   153.616913   \n",
       "\n",
       "       Dividend Yield (%)  \n",
       "69160            0.224510  \n",
       "69159            0.388210  \n",
       "69158            0.302334  \n",
       "69157            0.781250  \n",
       "69152            1.230159  \n",
       "...                   ...  \n",
       "56653            0.908998  \n",
       "56651            0.271045  \n",
       "56655            1.229907  \n",
       "56656            0.701915  \n",
       "56650            0.325485  \n",
       "\n",
       "[12511 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv('russel1000_dividend_last5years.csv')\n",
    "df.dropna(inplace=True)\n",
    "df.sort_values(by='Date', ascending=False, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6b7b7c3-c74b-4e83-86e6-1c9e71a621df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7871/2946310519.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"Last year Dividend Yield (%)\"].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# computing the last year dividend\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "# Define the date range for filtering\n",
    "start_date = \"2024-02-17\"\n",
    "end_date = \"2025-02-17\"\n",
    "\n",
    "# Filter data for the last year\n",
    "df_filtered = df[(df[\"Date\"] >= start_date) & (df[\"Date\"] <= end_date)]\n",
    "\n",
    "# Group by Ticker and sum Dividend Yield (%) for the last year\n",
    "df_grouped = df_filtered.groupby(\"Ticker\", as_index=False).agg(\n",
    "    {\"Dividend Yield (%)\": \"sum\"}\n",
    ")\n",
    "\n",
    "# Rename the column to \"Last year Dividend Yield (%)\"\n",
    "df_grouped.rename(columns={\"Dividend Yield (%)\": \"Last year Dividend Yield (%)\"}, inplace=True)\n",
    "\n",
    "# Merge back with the original df to retain all tickers\n",
    "df = df.merge(df_grouped, on=\"Ticker\", how=\"left\")\n",
    "\n",
    "# Fill NaN with 0 for tickers with no dividends in the date range\n",
    "df[\"Last year Dividend Yield (%)\"].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e1e95fd0-fd07-4d46-9f04-3de9d252977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted list of the last year dividend\n",
    "import heapq\n",
    "Threshold = 5\n",
    "stack = []\n",
    "heapq.heapify(stack)\n",
    "df.sort_values(by='Last year Dividend Yield (%)', ascending=False, inplace=True)\n",
    "for gr, gr_df in df.groupby(\"Ticker\"):\n",
    "    gr_df.reset_index(drop=True, inplace=True)\n",
    "    gr_df.sort_values(by=\"Date\", ascending=True, inplace=True)\n",
    "    dividend = gr_df.loc[0, 'Last year Dividend Yield (%)']\n",
    "    if dividend > Threshold:\n",
    "        heapq.heappush(stack, (-dividend, gr, gr_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "278d3641-e52c-49fb-89d7-92f48322bbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50d17890-504f-4a56-b580-0ce3a9bcdd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance sheet extractor\n",
    "# pip install edgartools\n",
    "import sys\n",
    "from edgar import *\n",
    "from edgar.financials import Financials\n",
    "import pandas as pd\n",
    "\n",
    "set_identity(\"sarashs arash.sheikh65@gmail.com\")\n",
    "\n",
    "from edgar import Company\n",
    "\n",
    "def fetch_10K_and_10Q_filings(ticker: str, start_date: str, end_date: str, form: list = ['10-K']):\n",
    "    \"\"\"\n",
    "    Fetches the 10-K and 10-Q filings for the given ticker within the specified date range.\n",
    "\n",
    "    Note:\n",
    "      - Make sure you have set your EDGAR identity (using set_identity) before calling this function.\n",
    "      - The date filter should be in the form \"YYYY-MM-DD:YYYY-MM-DD\".\n",
    "\n",
    "    Parameters:\n",
    "        ticker (str): The stock ticker (e.g., \"AAPL\").\n",
    "        start_date (str): The start date in \"YYYY-MM-DD\" format.\n",
    "        end_date (str): The end date in \"YYYY-MM-DD\" format.\n",
    "\n",
    "    Returns:\n",
    "        list: A list-like object of filing objects (or an empty list if no filings are found).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a Company object for the given ticker\n",
    "        company = Company(ticker)\n",
    "        # Retrieve both 10-K and 10-Q filings for the company\n",
    "        filings = company.get_filings(form=form) #\"10-K\",\n",
    "        # Filter the filings based on the provided date range\n",
    "        # The filter date string uses the format \"start_date:end_date\"\n",
    "        filtered_filings = filings.filter(date=f\"{start_date}:{end_date}\")\n",
    "        \n",
    "        if not filtered_filings:\n",
    "            print(f\"No 10-K or 10-Q filings found for {ticker} between {start_date} and {end_date}.\")\n",
    "            return []\n",
    "            \n",
    "        return filtered_filings\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while fetching filings for {ticker}: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def extract_financials(filings):\n",
    "    \"\"\"\n",
    "    Extracts financial statements from a list of filings.\n",
    "    \n",
    "    For each filing, the function:\n",
    "      - Calls filing.obj() to get the data object (e.g. TenK/TenQ).\n",
    "      - Checks that the object has a 'financials' attribute.\n",
    "      - Extracts the balance sheet, income statement, and cashflow statement using:\n",
    "            financials.get_balance_sheet()\n",
    "            financials.get_income_statement()\n",
    "            financials.get_cash_flow_statement()\n",
    "    \n",
    "    Parameters:\n",
    "        filings (list): A list-like object of filing objects (e.g. from Company.get_filings()).\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Three lists containing the extracted financial statements:\n",
    "               (balance_sheets, income_statements, cashflow_statements).\n",
    "               Filings that do not have a data object or the requested financial statement(s) are skipped.\n",
    "    \"\"\"\n",
    "    balance_sheets = []\n",
    "    income_statements = []\n",
    "    cashflow_statements = []\n",
    "    \n",
    "    for filing in filings:\n",
    "        try:\n",
    "            # Convert the filing to its data object (e.g., TenK or TenQ)\n",
    "            data_obj = filing.obj()\n",
    "            if data_obj is None:\n",
    "                print(\"Filing has no data object. Skipping...\")\n",
    "                continue\n",
    "            \n",
    "            # Check that the data object contains financials\n",
    "            if not hasattr(data_obj, \"financials\") or data_obj.financials is None:\n",
    "                print(\"Filing has no financials. Skipping...\")\n",
    "                continue\n",
    "\n",
    "            financials = data_obj.financials\n",
    "            \n",
    "            # Extract the individual financial statements.\n",
    "            # If any of these methods are unavailable or return None, skip that particular statement.\n",
    "            balance_sheet = financials.get_balance_sheet() if hasattr(financials, \"get_balance_sheet\") else None\n",
    "            income_statement = financials.get_income_statement() if hasattr(financials, \"get_income_statement\") else None\n",
    "            cashflow_statement = financials.get_cash_flow_statement() if hasattr(financials, \"get_cash_flow_statement\") else None\n",
    "            \n",
    "            if balance_sheet is not None:\n",
    "                balance_sheets.append(balance_sheet)\n",
    "            if income_statement is not None:\n",
    "                income_statements.append(income_statement)\n",
    "            if cashflow_statement is not None:\n",
    "                cashflow_statements.append(cashflow_statement)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting financials from filing: {e}\")\n",
    "            continue\n",
    "\n",
    "        # convert to string to be digested by OpenAI model\n",
    "        balance_sheets_str = '\\n'.join([item.to_dataframe().to_string() for item in balance_sheets])\n",
    "        income_statements_str = '\\n'.join([item.to_dataframe().to_string() for item in income_statements])\n",
    "        cashflow_statements_str = '\\n'.join([item.to_dataframe().to_string() for item in cashflow_statements])\n",
    "    \n",
    "    return balance_sheets, income_statements, cashflow_statements, balance_sheets_str, income_statements_str, cashflow_statements_str\n",
    "\n",
    "\n",
    "filings_list = fetch_10K_and_10Q_filings(\"AGNC\", \"2023-01-01\", \"2025-2-15\",form=[\"10-Q\", \"10-K\"])\n",
    "balance_sheets, income_statements, cashflow_statements, balance_sheets_str, income_statements_str, cashflow_statements_str = extract_financials(filings_list)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "499ce5cd-0198-43f4-86ff-1e737d4ccaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open ai financial health assessment\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "class Step(BaseModel):\n",
    "    justification: str\n",
    "\n",
    "class Assessment(BaseModel):\n",
    "    steps: list[Step]\n",
    "    trends: str\n",
    "    approve: bool\n",
    "    \n",
    "def assess(income_statements_str, cashflow_statements_str, balance_sheets_str):\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"o3-mini\",\n",
    "        reasoning_effort= \"high\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"\"\"You are a financial advisor. You are provided the last two years worth of financial data based on 10-K and 10-K documnent for a company.\n",
    "            The goal is to buy the most promising dividend stock. Whether or not a stock is a dividend stock is not for you to extract but you are looking at the financial health of the company and your primary goal is to avoid risk.\n",
    "            You must provide me with the trends over the past two years, your step by step justification of your assessment and whether or not you approve this purchase considering the potential risks to this company.\"\"\"},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"Here are the balance sheets, income statements, and cashflow statements for the past three years.\\n\\n\n",
    "            Income statements:\\n{income_statements_str}\\n\\nCashflow statements:\\n{cashflow_statements_str}\\n\\nBalance sheets:\\n{balance_sheets_str}\n",
    "            \"\"\"},\n",
    "        ],\n",
    "        response_format=Assessment,\n",
    "    )\n",
    "    \n",
    "    assessment = completion.choices[0].message.parsed\n",
    "    return assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d8910587-5c78-4e49-bf0c-0ac5fbc8a263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "from pprint import pp\n",
    "pp(assessment.approve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a40da76-2728-4ab7-8a4d-6e4a85caa8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                  | 0/56 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# processing the balance sheets\n",
    "from tqdm import tqdm\n",
    "balance_sheet_approved = {}\n",
    "for i in tqdm(range(len(stack))):\n",
    "    dividend, gr, gr_df = stack[i]\n",
    "    filings_list = fetch_10K_and_10Q_filings(gr, \"2023-01-01\", \"2025-2-15\",form=[\"10-Q\", \"10-K\"])\n",
    "    _, _, _, balance_sheets_str, income_statements_str, cashflow_statements_str = extract_financials(filings_list)\n",
    "    assessment = assess(income_statements_str, cashflow_statements_str, balance_sheets_str)\n",
    "    if assessment.approve:\n",
    "        balance_sheet_approved[gr] = (dividend, assessment.trends, gr_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9890e2e0-7baf-48ea-8ff0-668e9fcf9b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Russell 3000 tickers\n",
    "# You would typically get an updated list from an official source or file\n",
    "# Here is a placeholder list for demonstration purposes\n",
    "tickers = ['ASML', 'MSFT']  # Replace with the full Russell 3000 list\n",
    "\n",
    "# Initialize an empty DataFrame to store dividend data\n",
    "all_dividends = pd.DataFrame()\n",
    "all_prices = pd.DataFrame()\n",
    "\n",
    "for ticker in tickers:\n",
    "    stock = yf.Ticker(ticker)\n",
    "    \n",
    "    # Get dividend history\n",
    "    dividends = stock.dividends.reset_index()\n",
    "    dividends['Ticker'] = ticker\n",
    "    \n",
    "    # Get historical price data\n",
    "    prices = stock.history(period=\"max\").reset_index()[['Date', 'Close']]\n",
    "    prices['Ticker'] = ticker\n",
    "\n",
    "    # Append to the main DataFrames\n",
    "    all_dividends = pd.concat([all_dividends, dividends], ignore_index=True)\n",
    "    all_prices = pd.concat([all_prices, prices], ignore_index=True)\n",
    "\n",
    "# Set the date as the index\n",
    "all_dividends.set_index('Date', inplace=True)\n",
    "all_prices.set_index('Date', inplace=True)\n",
    "\n",
    "# Plotting dividends and prices for a specific ticker (e.g., 'AAPL')\n",
    "ticker_to_plot = 'ASML'\n",
    "\n",
    "div_data = all_dividends[all_dividends['Ticker'] == ticker_to_plot]\n",
    "price_data = all_prices[all_prices['Ticker'] == ticker_to_plot]\n",
    "\n",
    "# Aligning the indices to ensure proper plotting\n",
    "combined_data = pd.merge(price_data, div_data[['Dividends']], left_index=True, right_index=True, how='outer')\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot dividends as stem plot for better visibility\n",
    "ax1.stem(combined_data.index, combined_data['Dividends'].fillna(0), linefmt='blue', markerfmt='bo', basefmt=\" \", label='Dividends')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Dividends', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Plot price on the same graph with a different y-axis\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(combined_data.index, combined_data['Close'], color='red', label='Close Price')\n",
    "ax2.set_ylabel('Close Price', color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "# Add title and show the plot\n",
    "plt.title(f'{ticker_to_plot} Dividends and Close Price Over Time')\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Save to CSV (optional)\n",
    "# all_dividends.to_csv('russell3000_dividends.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1688f1f-aedc-410b-8cfa-fbe889aecc9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
