{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da2c450e-9cc4-47c4-90a8-427791123793",
   "metadata": {},
   "source": [
    "# Greenblatt Magic formula\n",
    "\n",
    "## The Magic Formula: Explanation and Formula\n",
    "\n",
    "The **Magic Formula** is an investment strategy developed by **Joel Greenblatt** to identify high-quality companies that are also undervalued. It ranks companies based on two key financial ratios:\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Core Idea\n",
    "\n",
    "> **Buy good companies at cheap prices.**\n",
    "\n",
    "The strategy identifies:\n",
    "- **\"Good companies\"** ‚Üí those with high returns on capital (efficient use of capital).\n",
    "- **\"Cheap companies\"** ‚Üí those with high earnings yield (undervalued based on operating profits).\n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ The original Formula\n",
    "\n",
    "1. **Earnings Yield (EY):**\n",
    "$$\n",
    "\\text{Earnings Yield} = \\frac{\\text{EBIT}}{\\text{Enterprise Value}}\n",
    "$$\n",
    "- Measures how cheap the stock is.\n",
    "- EBIT = Earnings Before Interest and Taxes\n",
    "- Enterprise Value = Market Cap + Debt - Cash\n",
    "\n",
    "2. **Return on Capital (ROC):**\n",
    "$$\n",
    "\\text{Return on Capital} = \\frac{\\text{EBIT}}{\\text{Net Working Capital} + \\text{Net Fixed Assets}}\n",
    "$$\n",
    "- Measures the quality of the business (how efficiently it uses its capital).\n",
    "### My filters\n",
    "1. Add minimum revenue\n",
    "2. Skip if net income is non-positive\n",
    "3. Skip (net_income > 0 and cashflow < 0) or (net_income < 0 and cashflow > 0)\n",
    "4. Operating expenses must be non-negative\n",
    "5. Exclude extreme accounting adjustments (per filteration in the code)\n",
    "6. Remove absurdly high EBIT margins (e.g., > 200%)\n",
    "---\n",
    "\n",
    "### ü§ñ LLM 10-K and earnings calls Analysis\n",
    "\n",
    "We further refine the outcomes of the Magic Formula for **domestic** stocks using 10-K filings and earnings calls by analyzing them through an LLM pipeline. This step allows for an additional qualitative screen, identifying potential red flags or strategic strengths that may not be captured in the numerical ranking alone.\n",
    "\n",
    "\n",
    "## üîç Implementation Steps\n",
    "\n",
    "1. **Filter the universe**: Remove financials, utilities, and companies with very small market cap.\n",
    "2. **Rank all remaining stocks** by:\n",
    "   - Earnings Yield (high = better)\n",
    "   - Return on Capital (high = better)\n",
    "3. **Compute combined rank**:\n",
    "   $$\n",
    "   \\text{Combined Rank} = \\text{Rank}_{EY} + \\text{Rank}_{ROC}\n",
    "   $$\n",
    "4. **Sort by Combined Rank** (lowest = best overall).\n",
    "5. **Pick top N stocks** (e.g., top 20‚Äì30).\n",
    "6. **Hold for 1 year**, rebalance annually.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Why It Works\n",
    "\n",
    "- Avoids paying too much for popular stocks.\n",
    "- Focuses on operationally efficient, consistently profitable companies.\n",
    "- Enforces a disciplined, rules-based approach.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Notes and Caveats\n",
    "\n",
    "- Avoids subjective judgement; however, **screening accuracy** depends on **quality of financial data**.\n",
    "- May underperform in short-term or irrational markets.\n",
    "- Works best over a multi-year horizon (3‚Äì5+ years).\n",
    "- I have separated this into US and International stocks.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51197021-515e-4963-a7b7-3a8075cc3eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "api_key = os.getenv('financial_modeling_prep_api_key')\n",
    "assert api_key is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da2bbc2-aec9-45a8-9bce-1095fb3281a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retry settings: 5 attempts with exponential backoff\n",
    "@retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=1, min=10, max=60))\n",
    "def fetch_json(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def get_magic_formula(api_key, symbols, minimum_margin=0.4, minimum_marketcap=500_000_000, minimum_revenue=100_000_000):\n",
    "    import pandas as pd\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    base_url = \"https://financialmodelingprep.com/stable\"\n",
    "    results = []\n",
    "\n",
    "    for symbol in tqdm(symbols, desc=\"Processing symbols\"):\n",
    "        try:\n",
    "            # Step 1: Check market cap\n",
    "            ev_url = f\"{base_url}/enterprise-values/?symbol={symbol}&apikey={api_key}\"\n",
    "            ev_data = fetch_json(ev_url)[0]\n",
    "            market_cap = ev_data.get('marketCapitalization')  \n",
    "            \n",
    "            if not ev_data or market_cap < minimum_marketcap:\n",
    "                continue\n",
    "\n",
    "            # Step 2: Exclude financials and real estate sectors\n",
    "            profile_url = f\"{base_url}/profile?symbol={symbol}&apikey={api_key}\"\n",
    "            profile_data = fetch_json(profile_url)\n",
    "            sector = profile_data[0].get('sector') \n",
    "            company_name = profile_data[0].get('companyName')\n",
    "            \n",
    "            if not profile_data or sector in ['Financial Services', 'Real Estate']:\n",
    "                continue\n",
    "\n",
    "            # Step 3: Fetch income statement\n",
    "            income_url = f\"{base_url}/income-statement/?symbol={symbol}&apikey={api_key}\"\n",
    "            income_data = fetch_json(income_url)[0]\n",
    "            net_income = income_data.get('netIncome')\n",
    "            revenue = income_data.get('revenue')\n",
    "\n",
    "            # Filter: minimum revenue\n",
    "            if revenue < minimum_revenue:\n",
    "                continue\n",
    "\n",
    "            # Skip if net income is non-positive (net_income > 0 and cashflow < 0) or (net_income < 0 and cashflow > 0)\n",
    "            if net_income is None or net_income <= 0:\n",
    "                continue\n",
    "\n",
    "            cash_url = f\"{base_url}/cash-flow-statement/?symbol={symbol}&apikey={api_key}\"\n",
    "            cash_data = fetch_json(cash_url)[0]\n",
    "            cashflow = cash_data['operatingCashFlow']\n",
    "            \n",
    "            #if abs(net_income - cashflow) > 0.5 * net_income:\n",
    "            if (net_income > 0 and cashflow < 0) or (net_income < 0 and cashflow > 0):\n",
    "                print(f\"Cashflow mismatch for {symbol}\")\n",
    "                continue  # net income not supported by cash flow\n",
    "\n",
    "            # Step 4: Fetch balance sheet\n",
    "            balance_url = f\"{base_url}/balance-sheet-statement/?symbol={symbol}&apikey={api_key}\"\n",
    "            balance_data = fetch_json(balance_url)[0]\n",
    "\n",
    "            # Step 5: Fetch dividend\n",
    "            dividend = f\"{base_url}/dividends/?symbol={symbol}&apikey={api_key}\"\n",
    "            dividend_data = fetch_json(dividend)\n",
    "            dividend = 0\n",
    "            if dividend_data:\n",
    "                dividend_data = dividend_data[0]\n",
    "                dividend = dividend_data.get('yield')\n",
    "                div_date = dividend_data.get('date')\n",
    "\n",
    "            # Extract relevant fields\n",
    "            ebit = income_data.get('ebit')\n",
    "            \n",
    "            total_assets = balance_data.get('totalAssets')\n",
    "            current_liabilities = balance_data.get('totalCurrentLiabilities')\n",
    "            enterprise_value = ev_data.get('enterpriseValue')\n",
    "            operating_expenses = income_data.get('operatingExpenses')\n",
    "            other_expenses = income_data.get('otherExpenses')\n",
    "\n",
    "            # Ensure all required fields are present\n",
    "            if None in (ebit, revenue, total_assets, current_liabilities, enterprise_value):\n",
    "                print(f\"missing data for {symbol}\")\n",
    "                continue\n",
    "\n",
    "            # Filter: Operating expenses must be non-negative\n",
    "            if operating_expenses is not None and operating_expenses < 0:\n",
    "                continue\n",
    "\n",
    "            # Filter: exclude extreme accounting adjustments\n",
    "            if other_expenses is not None and other_expenses < -revenue:\n",
    "                continue\n",
    "\n",
    "            # Filter: remove absurdly high EBIT margins (e.g., > 200%)\n",
    "            ebit_margin = ebit / revenue\n",
    "            if ebit_margin < minimum_margin or ebit_margin > 2:\n",
    "                continue\n",
    "\n",
    "            # Compute Greenblatt metrics\n",
    "            earnings_yield = ebit / enterprise_value\n",
    "            capital = total_assets - current_liabilities\n",
    "            if capital <= 0:\n",
    "                continue\n",
    "            return_on_capital = ebit / capital\n",
    "\n",
    "            # Append result\n",
    "            results.append({\n",
    "                'symbol': symbol,\n",
    "                'company_name': company_name,\n",
    "                'dividend': dividend,\n",
    "                'div date': div_date,\n",
    "                'sector' : sector,\n",
    "                'ebit_margin': ebit_margin,\n",
    "                'earnings_yield': earnings_yield,\n",
    "                'return_on_capital': return_on_capital\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Symbol: {symbol}\\n')\n",
    "            print(e)\n",
    "\n",
    "    # Step 6: Compile DataFrame and rank\n",
    "    df = pd.DataFrame(results)\n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    df['ey_rank'] = df['earnings_yield'].rank(ascending=False)\n",
    "    df['roc_rank'] = df['return_on_capital'].rank(ascending=False)\n",
    "    df['combined_rank'] = df['ey_rank'] + df['roc_rank']\n",
    "    df_sorted = df.sort_values(by='combined_rank')\n",
    "\n",
    "    return df_sorted #[['symbol', 'ebit_margin', 'earnings_yield', 'return_on_capital', 'combined_rank']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb314d09-f460-447d-ad71-ca056a171d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = pd.read_csv(\"russel1000.csv\")\n",
    "symbols = symbols['Ticker'].to_list()\n",
    "\n",
    "top_stocks = get_magic_formula(api_key, symbols, minimum_marketcap=50_000_000, minimum_margin=0.05, minimum_revenue=0)\n",
    "\n",
    "print(top_stocks)\n",
    "russel1000_filtered = top_stocks\n",
    "russel1000_filtered.to_csv('russel1000_magic_formula.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cf78d5-acc4-4bea-851c-790a3f69e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = pd.read_csv(\"all_listed_companies.csv\")\n",
    "russel_symbols = pd.read_csv(\"russel1000.csv\")['Ticker'].to_list()\n",
    "symbols = symbols[~symbols['Symbol'].isin(russel_symbols)]['Symbol'].to_list()\n",
    "\n",
    "top_stocks = get_magic_formula(api_key, symbols, minimum_marketcap=50_000_000, minimum_margin=0.05, minimum_revenue=0)\n",
    "print(top_stocks)\n",
    "world_filtered = top_stocks\n",
    "world_filtered.head(60).to_csv('world_magic_formula.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29762291-849a-4e72-be2b-3022d0ca45f0",
   "metadata": {},
   "source": [
    "## AI Driven Analysis on 10-K documents and earnings calls for domestic stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bc64af-8807-41aa-a6d7-3997a6e6451a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.append(\"../\")\n",
    "import importlib\n",
    "import wallstreet_quant.edgar_pipeline  # or from wallstreet_quant import edgar_pipeline\n",
    "\n",
    "importlib.reload(wallstreet_quant.edgar_pipeline)\n",
    "from wallstreet_quant.edgar_pipeline import SecAnalysis\n",
    "from wallstreet_quant.edgar_extractor import fetch_10K_and_10Q_filings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3d963a-0227-445b-9c81-72ff83da7c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "russel1000_filtered = pd.read_csv('russel1000_magic_formula.csv').head(80)\n",
    "sec_ai = SecAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b9affd-cb8f-47e5-b6d7-2359421b0191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "filings = defaultdict(list)\n",
    "for s in tqdm(russel1000_filtered['symbol']):\n",
    "    try:\n",
    "        filings[s] = fetch_10K_and_10Q_filings(s, \"2023-01-01\", \"2025-6-6\",form=[\"10-K\"])\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcab78b-9675-4ec1-a70c-d0b7b5c96d74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = sec_ai(filings, model = \"gpt-4o\")  \n",
    "df.to_excel('russel1000_magic_formula_gpt_analysis.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5104d9-f94a-413a-93b8-5735d707bfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7734199-9c3b-498e-a469-30ec2b0f81e6",
   "metadata": {},
   "source": [
    "# Clustering the domestic stocks for diversification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49275a5-a863-4075-9baa-f42057583752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_excel('russel1000_magic_formula_gpt_analysis.xlsx') #russel1000_magic_formula_gpt_analysis\n",
    "try:\n",
    "    tickers = df['ticker'].to_list()\n",
    "except:\n",
    "    tickers = df['symbol'].to_list()\n",
    "price_frames   = []\n",
    "existing=[]\n",
    "for symbol in tickers:\n",
    "    try:\n",
    "        tk = yf.Ticker(symbol)\n",
    "\n",
    "        # Daily adjusted close (already adjusted when auto_adjust=True)\n",
    "        hist = tk.history(start=\"2025-01-01\", auto_adjust=True)[['Close']]\n",
    "        hist = hist.rename(columns={'Close': symbol})\n",
    "        price_frames.append(hist)\n",
    "        existing.append(symbol)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {symbol}: {e}\")\n",
    "\n",
    "# Align prices on common dates\n",
    "prices = pd.concat(price_frames, axis=1, join='inner').sort_index()\n",
    "\n",
    "# Log-returns\n",
    "returns = np.log(prices / prices.shift(1)).dropna()\n",
    "\n",
    "# Normalized covariance matrix\n",
    "cov_matrix = returns.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a36b56-f54a-4028-8cd5-c9f34ef1d08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import GraphicalLassoCV\n",
    "from sklearn import cluster\n",
    "\n",
    "# X: rows = time steps (samples), columns = assets\n",
    "X = returns[existing].to_numpy()\n",
    "\n",
    "# Standardize data (optional but common)\n",
    "X -= X.mean(axis=0)\n",
    "X /= X.std(axis=0)\n",
    "\n",
    "# Fit Graphical Lasso with cross-validated alpha\n",
    "model = GraphicalLassoCV(alphas=np.logspace(-2, 2, 20))\n",
    "model.fit(X)\n",
    "\n",
    "# The estimated sparse inverse covariance matrix (precision)\n",
    "precision_matrix = model.precision_\n",
    "# The estimated covariance matrix\n",
    "covariance_matrix = model.covariance_\n",
    "\n",
    "_, labels = cluster.affinity_propagation(model.covariance_, random_state=0)\n",
    "n_labels = labels.max()\n",
    "symbols = np.array(existing)\n",
    "\n",
    "clusterdict = {}\n",
    "for i in range(n_labels + 1):\n",
    "    print(f\"Cluster {i + 1}: {', '.join(symbols[labels == i])}\")\n",
    "try:\n",
    "    df = df[df['ticker'].isin(existing)]\n",
    "except:\n",
    "    df = df[df['symbol'].isin(existing)]\n",
    "\n",
    "df['cluster'] = labels\n",
    "df.to_excel('russel1000_magic_formula_gpt_analysis.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483ba05a-e498-475d-98da-135975bdc2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import manifold\n",
    "\n",
    "node_position_model = manifold.LocallyLinearEmbedding(\n",
    "    n_components=2, eigen_solver=\"dense\", n_neighbors=2\n",
    ")\n",
    "\n",
    "embedding = node_position_model.fit_transform(X.T).T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "plt.figure(1, facecolor=\"w\", figsize=(10, 8))\n",
    "plt.clf()\n",
    "ax = plt.axes([0.0, 0.0, 1.0, 1.0])\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Plot the graph of partial correlations\n",
    "partial_correlations = model.precision_.copy()\n",
    "d = 1 / np.sqrt(np.diag(partial_correlations))\n",
    "partial_correlations *= d\n",
    "partial_correlations *= d[:, np.newaxis]\n",
    "non_zero = np.abs(np.triu(partial_correlations, k=1)) > 0.02\n",
    "\n",
    "# Plot the nodes using the coordinates of our embedding\n",
    "plt.scatter(\n",
    "    embedding[0], embedding[1], s=100 * d**2, c=labels, cmap=plt.cm.nipy_spectral\n",
    ")\n",
    "\n",
    "# Plot the edges\n",
    "start_idx, end_idx = np.where(non_zero)\n",
    "# a sequence of (*line0*, *line1*, *line2*), where::\n",
    "#            linen = (x0, y0), (x1, y1), ... (xm, ym)\n",
    "segments = [\n",
    "    [embedding[:, start], embedding[:, stop]] for start, stop in zip(start_idx, end_idx)\n",
    "]\n",
    "values = np.abs(partial_correlations[non_zero])\n",
    "lc = LineCollection(\n",
    "    segments, zorder=0, cmap=plt.cm.hot_r, norm=plt.Normalize(0, 0.7 * values.max())\n",
    ")\n",
    "lc.set_array(values)\n",
    "lc.set_linewidths(15 * values)\n",
    "ax.add_collection(lc)\n",
    "\n",
    "# Add a label to each node. The challenge here is that we want to\n",
    "# position the labels to avoid overlap with other labels\n",
    "for index, (name, label, (x, y)) in enumerate(zip(tickers, labels, embedding.T)):\n",
    "    dx = x - embedding[0]\n",
    "    dx[index] = 1\n",
    "    dy = y - embedding[1]\n",
    "    dy[index] = 1\n",
    "    this_dx = dx[np.argmin(np.abs(dy))]\n",
    "    this_dy = dy[np.argmin(np.abs(dx))]\n",
    "    if this_dx > 0:\n",
    "        horizontalalignment = \"left\"\n",
    "        x = x + 0.002\n",
    "    else:\n",
    "        horizontalalignment = \"right\"\n",
    "        x = x - 0.002\n",
    "    if this_dy > 0:\n",
    "        verticalalignment = \"bottom\"\n",
    "        y = y + 0.002\n",
    "    else:\n",
    "        verticalalignment = \"top\"\n",
    "        y = y - 0.002\n",
    "    plt.text(\n",
    "        x,\n",
    "        y,\n",
    "        name,\n",
    "        size=10,\n",
    "        horizontalalignment=horizontalalignment,\n",
    "        verticalalignment=verticalalignment,\n",
    "        bbox=dict(\n",
    "            facecolor=\"w\",\n",
    "            edgecolor=plt.cm.nipy_spectral(label / float(n_labels)),\n",
    "            alpha=0.6,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "plt.xlim(\n",
    "    embedding[0].min() - 0.15 * np.ptp(embedding[0]),\n",
    "    embedding[0].max() + 0.10 * np.ptp(embedding[0]),\n",
    ")\n",
    "plt.ylim(\n",
    "    embedding[1].min() - 0.03 * np.ptp(embedding[1]),\n",
    "    embedding[1].max() + 0.03 * np.ptp(embedding[1]),\n",
    ")\n",
    "\n",
    "#plt.savefig(\"covariance_graph.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa161bc-7726-4166-874f-0e03926dba4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
